{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Solucionario Clase 1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AQ7QV0ib2Xu2",
        "ZChnkpQM8GSm",
        "B9sM6P7E7dZC"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wJV_1sXR8JX"
      },
      "source": [
        "# Mini desafíos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve8-YdUyagnD"
      },
      "source": [
        "### Mini desafío 1.A\n",
        "Leer el archivo **Tabla1.xlsx** que contiene los puntos de un campeonato. El archivo tiene cuatro columnas, **Equipo**, **Puntos**, **Goles a favor** y **Goles en contra**. Determinar de cada equipo la diferencia de gol (goles a favor - goles en contra), y mostrar todas las diferencias de gol usando **print**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efoMZn5096BH"
      },
      "source": [
        " ! wget \"https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/Tabla1.xlsx\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz5SB4ReSLae"
      },
      "source": [
        "**Solución 1** - La primera solución es con el comando **to_dict(\"list\")**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83Rg45ylSL7E",
        "outputId": "d6100c54-79c3-40c2-896a-a15d94490f12"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "archivo = pd.read_excel(\"Tabla1.xlsx\")\n",
        "\n",
        "data = archivo.to_dict(\"list\") # diccionario de listas.\n",
        "#La clave de los diccionarios es el nombre de la columna\n",
        "#El contenido de los diccionarios es una lista con el contenido de la columna\n",
        "\n",
        "filas = len(data[\"Equipo\"])\n",
        "\n",
        "print(\"Diferencias de gol:\")\n",
        "\n",
        "for i in range(len(data[\"Equipo\"])):\n",
        "    print(data[\"Equipo\"][i], \":\", data[\"Goles a favor\"][i] - data[\"Goles en contra\"][i])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diferencias de gol:\n",
            "Equipo A : 55\n",
            "Equipo B : 30\n",
            "Equipo C : 40\n",
            "Equipo D : -30\n",
            "Equipo E : -5\n",
            "Equipo F : 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk069MjXSPJ7"
      },
      "source": [
        "**Solución 2** - La segunda solución es con el comando **to_dict(\"records\")**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llvohcJSSRau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "961017b1-c450-42b0-f403-af2873ea1032"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "archivo = pd.read_excel(\"Tabla1.xlsx\")\n",
        "\n",
        "data = archivo.to_dict(\"records\") # lista de diccionarios\n",
        "# cada elemento de la lista es un diccionario que contiene los valores de cada fila\n",
        "\n",
        "print(\"Diferencias de gol:\")\n",
        "\n",
        "for i in range(len(data)):\n",
        "    print(data[i][\"Equipo\"], \":\", data[i][\"Goles a favor\"] - data[i][\"Goles en contra\"])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diferencias de gol:\n",
            "Equipo A : 55\n",
            "Equipo B : 30\n",
            "Equipo C : 40\n",
            "Equipo D : -30\n",
            "Equipo E : -5\n",
            "Equipo F : 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kt4VjWjSTpM"
      },
      "source": [
        "**Solución 3**  - La tercera solución es con el comando **to_dict(\"index\")**. Se indexa por el nombre de los equipos que debe ser unico de cada equipo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CRRMQCXSVDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "697eff90-44d2-42a3-c478-15aa9754f319"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "archivo = pd.read_excel(\"Tabla1.xlsx\", index_col=\"Equipo\")\n",
        "\n",
        "data = archivo.to_dict(\"index\") # diccionario de diccionarios\n",
        "# la clave de cada campo del diccionario es el nombre del equipo (index_col)\n",
        "# el contenido de cada campo del diccionario es un diccionario con la información del equipo\n",
        "\n",
        "print(\"Diferencias de gol:\")\n",
        "\n",
        "for equipo in data.keys():\n",
        "    print(equipo, \":\", data[equipo][\"Goles a favor\"] - data[equipo][\"Goles en contra\"])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diferencias de gol:\n",
            "Equipo A : 55\n",
            "Equipo B : 30\n",
            "Equipo C : 40\n",
            "Equipo D : -30\n",
            "Equipo E : -5\n",
            "Equipo F : 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjqvtRgg8LRG"
      },
      "source": [
        "### Mini desafío 1.B - Challenge\n",
        "\n",
        "Leer el archivo **Tabla1.xlsx** que contiene los puntos de un campeonato y determinar qué equipo es el campeón (**1ro**) y perdedor (**último**). El archivo tiene cuatro columnas, **Equipo**, **Puntos**, **Goles a favor** y **Goles en contra**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GStce2GfSZqa"
      },
      "source": [
        " ! wget \"https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/Tabla1.xlsx\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0wNgRLISbgw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25d514dc-447d-466e-925e-d79b408ad703"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "archivo = pd.read_excel(\"Tabla1.xlsx\", index_col = \"Equipo\") \n",
        "# Indicamos que la columna de indexación será Equipo.\n",
        "data = archivo.to_dict(\"index\") \n",
        "# \"index\" significa que vamos a obtener el contenido como diccionarios \n",
        "# donde la clave es algun campo de cada fila, en este caso la clave de los \n",
        "# diccionarios será la clave \"Equipo\"\n",
        "\n",
        "# print(data)\n",
        "\n",
        "maxpunt = 0\n",
        "minpunt = 1000000\n",
        "maxname = ''\n",
        "minname = ''\n",
        "\n",
        "# Vamos guardando y actualizando los \"récords\" mientras analizamos cada equipo\n",
        "for key in data.keys():\n",
        "    punt = data[key]['Puntos']\n",
        "    if punt > maxpunt:\n",
        "        maxpunt=punt\n",
        "        maxname = key\n",
        "    if punt < minpunt:\n",
        "        minpunt=punt\n",
        "        minname = key\n",
        "\n",
        "print(maxname, 'resultó campeón con', maxpunt, 'puntos.' )\n",
        "print(minname, 'resultó último con', minpunt, 'puntos.' )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equipo A resultó campeón con 30 puntos.\n",
            "Equipo D resultó último con 17 puntos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXIq2D1mSd_p"
      },
      "source": [
        "**Solución 2** - Esta solución es un poco más práctica y versátil"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwgWBQ4vSflD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88f57439-ce7a-41ce-e587-c4441aea3224"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "archivo = pd.read_excel(\"Tabla1.xlsx\", index_col =\"Equipo\") \n",
        "# Indicamos que la columna de indexación será Equipo.\n",
        "\n",
        "data = archivo.to_dict(\"index\")\n",
        "\n",
        "data_tuple = data.items() # provocamos que los datos esten como una lista de la forma (clave, contenido)\n",
        "\n",
        "def criterioDeOrden(item): # esta función determina el criterio de orden\n",
        "    clave, contenido = item\n",
        "    return contenido[\"Puntos\"] # indicamos que al criterio le importa los puntos\n",
        "\n",
        "data_ordenada = sorted(data_tuple, reverse=True, key=criterioDeOrden)\n",
        "\n",
        "ganador = data_ordenada[0][0] # el primer 0 indica que es el primer elemento (el ganador), el segundo 0 indica que nos interesa la clave (si fuera un 1 sería el contenido)\n",
        "perdedor = data_ordenada[-1][0] # el primer -1 indica que es el utimo elemento (el perdedor), el segundo 0 indica que nos interesa la clave (si fuera un 1 sería el contenido)\n",
        "\n",
        "print(ganador,\"resulto campeón con\",data[ganador][\"Puntos\"],\"puntos\")\n",
        "print(perdedor,\"resulto último con\", data[perdedor][\"Puntos\"],\"puntos\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equipo A resulto campeón con 30 puntos\n",
            "Equipo D resulto último con 17 puntos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4EY947g5RSL"
      },
      "source": [
        "### Mini desafío 2.A\n",
        "Calcular el promedio de las notas de química de todos los alumnos en el archivo **Datos.xlsx**.\n",
        "\n",
        "- **Tip:** Podemos usar la función **sum**($iterable$) para obtener la suma de todos los campos. Un ejemplo de como funciona:\n",
        "```python\n",
        "mi_lista = [1, 2, 3, 4, 5]\n",
        "total = sum(mi_lista)\n",
        "print(total)\n",
        "```\n",
        " ¡La función **len()** también sigue siendo válida!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Oivnx4DSktO"
      },
      "source": [
        "! wget \"https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/Datos.xlsx\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K02PVc4fSl-F",
        "outputId": "53d6bd2e-15a2-42d9-db32-8cb1aaa4deab"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "datos = pd.read_excel(\"Datos.xlsx\") \n",
        "data = datos['Quimica']\n",
        "\n",
        "print(sum(data) / len(data))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oloubsnc6nKD"
      },
      "source": [
        "### Mini desafío 2.B\n",
        "\n",
        "Escribir una funcion que reciba como parámetros: una variable de tipo **DataFrame** (la tabla de alumnos) y el índice de un alumno. Luego debe devolver con *return* el promedio de sus notas en las diferentes materias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI6XqLdgSqcQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7fe46d5-a926-4c3d-9e15-02714790236f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def promedio(df, index):\n",
        "    alumno = df.loc[index]\n",
        "    m = alumno[\"Matematica\"]\n",
        "    f = alumno[\"Fisica\"]\n",
        "    q = alumno[\"Quimica\"]\n",
        "    return (m + f + q)/3\n",
        "    \n",
        "datos = pd.read_excel(\"Datos.xlsx\")\n",
        "\n",
        "print(\"El promedio del dato 0 es %0.2f \" % promedio(datos, 0))\n",
        "print(\"El promedio del dato 1 es %0.2f \" % promedio(datos, 1))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El promedio del dato 0 es 8.67 \n",
            "El promedio del dato 1 es 5.67 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpPtaI977eSc"
      },
      "source": [
        "### Mini desafío 3\n",
        "\n",
        "Obtener el promedio general sólo para aquellos alumnos que aprobaron Matemática en el archivo **Datos.xlsx**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DffpeOF8Su2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2f521c-d161-4058-f0fa-2f14d7e50522"
      },
      "source": [
        "aprobadosMate = datos[(datos['Matematica']>=6)]\n",
        "promedios = (aprobadosMate[\"Quimica\"] + aprobadosMate[\"Matematica\"] + aprobadosMate[\"Fisica\"])/3\n",
        "\n",
        "promedio_general = sum(promedios)/len(promedios)\n",
        "\n",
        "print(\"El promedio general es %0.2f \" % promedio_general)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El promedio general es 7.78 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpKHSTPMR3tr"
      },
      "source": [
        "# Ejercitación integradora $\\newcommand{\\dif}{\\bigstar}$$\\newcommand{\\facil}{\\color{\\green}{\\dif}}$ $\\newcommand{\\pieceofcake}{\\color{\\cyan}{\\dif}}$$\\newcommand{\\medio}{\\color{\\yellow}{\\dif\\dif}}$$\\newcommand{\\media}{\\medio}$$\\newcommand{\\normal}{\\medio}$  $\\newcommand{\\dificil}{\\color{\\orange}{\\dif\\dif\\dif}}$ $\\newcommand{\\imposible}{\\color{\\red}{\\dif\\dif\\dif\\dif}}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGZb_d6BGXIv"
      },
      "source": [
        "## $\\facil$ Copy\n",
        "*   **Uso de librerías**\n",
        "*   **Manejo de archivos**\n",
        "\n",
        "Armar una función que copie un archivo *.xlsx*, y lo guarde como \"Copia 1 - $nombre$\", de ya existir debe guardarlo como Copia 2 -, Copia 3 - , ...\n",
        "\n",
        "Usar la libreria **os** para chequear si existe el archivo:\n",
        "\n",
        "Tips:\n",
        "\n",
        "- os.path.exists($nombre$) devolverá True si ya existe\n",
        "\n",
        "- Se puede importar con: `import os`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXq-llQpISeR"
      },
      "source": [
        "### **Solución**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChcJscsB0tbE"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def func(nombre):\n",
        "    repeticion = 1\n",
        "\n",
        "    while os.path.exists(\"Copia \" + str(repeticion) + \" \"+ nombre):\n",
        "        repeticion += 1\n",
        "        \n",
        "    shutil.copyfile(nombre, \"Copia \" + str(repeticion) + \" \"+ nombre)\n",
        "    \n",
        "        \n",
        "func('Tabla1.xlsx')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE3a2Dx3GhKx"
      },
      "source": [
        "## $\\facil$ California Housing\n",
        "\n",
        "*   ***Analísis de información estructurada***\n",
        "*   ***Librerías***\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn0nVqJrGhKz"
      },
      "source": [
        "# Importar el archivo california_housing_train.xlsx.\n",
        "! wget \"https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/california_housing_train.xlsx\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egvmBjEmGhK1"
      },
      "source": [
        "Este archivo contiene un conjunto de datos de viviendas de California, el cual fue extraido del censo de nacional de 1990. Para mas info sobre el set de datos: https://developers.google.com/machine-learning/crash-course/california-housing-data-description\n",
        "\n",
        "Extraer la siguiente información:\n",
        "\n",
        "*   ¿Cuantas casas hay con valor 'median_house_value' mayor a 80000 tomando de la longitud -120  a -118? Rta: 5466\n",
        "*   ¿Cual es el promedio de habitaciones por manzana ('total_rooms') de estas casas? Rta: 2466.31\n",
        "\n",
        "*   ¿Cual es la casa más cara? ¿Cuántas hay con este valor? Rta: 500001.0 - 814 \n",
        "\n",
        "*   $\\medio$ Obtener la media y la varianza de la propiedad 'median_house_value'. Rta: 207300.91 - 13451442293.57\n",
        "\n",
        "**Tip:** ¡Pueden investigar funciones de numpy para conseguir la media y la varianza!  [numpy.var](https://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.var.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M60NmSBgITXv"
      },
      "source": [
        "### **Solución**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4eMHo5N1D6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078dc8db-ea7d-4a3d-8f33-c6421e8dbbfb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "archivo = pd.read_excel(\"california_housing_train.xlsx\") \n",
        "\n",
        "#Pregunta 1 y 2 (utilizando filtrado)\n",
        "ans = 0\n",
        "hab = 0\n",
        "filtro_lon = (-120 <= archivo['longitude']) & (archivo['longitude'] <= -118)\n",
        "filtro_val = archivo['median_house_value'] > 80000\n",
        "ans = len( archivo[filtro_lon & filtro_val] )\n",
        "hab = sum(archivo[filtro_lon & filtro_val]['total_rooms'])\n",
        "print(ans)\n",
        "print(hab/ans)\n",
        "\n",
        "#Pregunta 1 y 2 (sin utilizar filtrado)\n",
        "ans = 0\n",
        "hab = 0\n",
        "for i,lon in enumerate(archivo['longitude']):\n",
        "    if -120 <= lon and lon<=-118 :\n",
        "        if archivo['median_house_value'][i] > 80000:\n",
        "            ans+=1\n",
        "            hab+=archivo['total_rooms'][i]\n",
        "print(ans)\n",
        "print(hab/ans)\n",
        "\n",
        "#Pregunta 3\n",
        "m = max(archivo['median_house_value'])\n",
        "c = sum(archivo['median_house_value'] == m)\n",
        "print(m)\n",
        "print(c)\n",
        "\n",
        "#pregunta 4\n",
        "m = np.mean(archivo['median_house_value'])\n",
        "v = np.var(archivo['median_house_value'])\n",
        "print(m)\n",
        "print(v)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5466\n",
            "2466.3122941822176\n",
            "5466\n",
            "2466.3122941822176\n",
            "500001\n",
            "814\n",
            "207300.91235294117\n",
            "13451442293.568731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN3fQAn0P4xu"
      },
      "source": [
        "## $\\medio$ Llévame en tu bicicleta\n",
        "\n",
        "*   ***Analisís de información estructurada***\n",
        "*   ***Librerías***\n",
        "\n",
        "El gobierno de la Ciudad de Buenos Aires recolecta datos acerca del uso de los servicios de bicicletas públicas (ecobici) y publica parte de ellos:\n",
        "https://data.buenosaires.gob.ar/dataset/bicicletas-publicas\n",
        "\n",
        "Para este ejemplo usaremos los primeros 10000 viajes de la base de datos del 2021. Están invitados a analizar todos los viajes, pero para ello les recomendamos descargar el archivo y ejecutar su programa en forma local (no en Google Golab).\n",
        "\n",
        "Se quiere conocer más acerca del uso que le dan los usuarios al sistema, por lo cual su tarea será extraer la siguiente información:\n",
        "\n",
        "* ¿Qué porcentaje de los viajes se completaron en estado NORMAL?\n",
        "* ¿Cuál es la duración promedio de cada viaje? (Los datos están en segundos)\n",
        "* ¿A qué hora del día se realizaron más viajes? (por ejemplo: de 16hs a 17hs)\n",
        "* ¿Cuántas estaciones diferentes fueron utilizadas?\n",
        "* Para cada estación utilizada como inicio de un viaje, imprimirlas ordenadas por cantidad de viajes que iniciaron de la misma.\n",
        "\n",
        "**Tip:** Recuerden investigar los métodos que tienen los DataFrames para ver si alguno de ellos les ayuda a resolver un problema particular.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RGcIi4eb09D"
      },
      "source": [
        "### **Solución**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee2IQo1iG8ej"
      },
      "source": [
        "# Una vez descargado el archivo se llamará \"recorridos-realizados-2021-sample.csv\"\n",
        "! wget \"https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/recorridos-realizados-2021-sample.csv\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "archivo = pd.read_csv(\"recorridos-realizados-2021-sample.csv\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RxR2BEpR2T9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57aa28bd-7b06-477d-eb4a-87d269620590"
      },
      "source": [
        "# Obtenemos el número de filas en el archivo\n",
        "numero_de_filas = len(archivo)\n",
        "\n",
        "# Usamos .value_counts() para obtener una cuenta de cuantas veces ocurre cada valor\n",
        "# Dividimos la cantidad de veces que aparece 'NORMAL' por la cantidad de filas\n",
        "estado_count = archivo['Estado cerrado'].value_counts()\n",
        "porcentaje_normal = 100*(estado_count['NORMAL'] / numero_de_filas)\n",
        "print(f'El {porcentaje_normal:.2f}% de los viajes se completaron en estado NORMAL')\n",
        "\n",
        "# Usamos .mean() para calcular el promedio\n",
        "duracion_promedio = round(archivo['Duración'].mean())\n",
        "print(f'La duración promedio es de {duracion_promedio//60} minutos {duracion_promedio%60} segundos')\n",
        "\n",
        "# Con pd.to_datetime() convertimos strings a objetos datetime\n",
        "# Usamos .dt.hour para obtener únicamente el valor de hora\n",
        "# Con .value_counts() y luego .idxmax() encontramos el índice que más veces aparece\n",
        "horarios_de_inicio = archivo['Fecha de inicio']\n",
        "horarios_de_inicio = pd.to_datetime(horarios_de_inicio)\n",
        "horas_de_inicio = horarios_de_inicio.dt.hour\n",
        "hora_pico = horas_de_inicio.value_counts().idxmax()\n",
        "print(f'La hora más concurrida es de {hora_pico}hs a {hora_pico+1}hs')\n",
        "\n",
        "# Con pd.concat unimos las columnas de estaciones de inicio y fin,\n",
        "# en caso de que una estación aparece sólo en una de ellas\n",
        "# Usando len() y .value_counts() encontramos la cantidad total de estaciones\n",
        "estaciones_inicio = archivo['Nombre de estación de inicio']\n",
        "estaciones_fin = archivo['Nombre de estación de fin de viaje']\n",
        "estaciones_total = pd.concat([estaciones_inicio, estaciones_fin])\n",
        "print(f'Se utilizaron {len(estaciones_total.value_counts())} estaciones en total')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El 97.88% de los viajes se completaron en estado NORMAL\n",
            "La duración promedio es de 18 minutos 10 segundos\n",
            "La hora más concurrida es de 15hs a 16hs\n",
            "Se utilizaron 230 estaciones en total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69rnv5AFbmQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f75d33af-cb88-4d83-c074-9734f4cfaa4f"
      },
      "source": [
        "# Usando .value_counts().iteritems() podemos recorrer las estaciones ordenadas\n",
        "# por la cantida de veces que aparece cada una\n",
        "\n",
        "print('\\nCantidad de viajes iniciados en cada estación:\\n')\n",
        "for estacion, cantidad in estaciones_inicio.value_counts().iteritems():\n",
        "  print('Cantidad:', cantidad, ' Estación:', estacion)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cantidad de viajes iniciados en cada estación:\n",
            "\n",
            "Cantidad: 120  Estación: 005 - Plaza Italia\n",
            "Cantidad: 117  Estación: 147 - Constitución\n",
            "Cantidad: 107  Estación: 113 - Guatemala\n",
            "Cantidad: 106  Estación: 161 - Humahuaca\n",
            "Cantidad: 103  Estación: 009 - Parque Las Heras\n",
            "Cantidad: 101  Estación: 014 - Pacifico\n",
            "Cantidad: 101  Estación: 074 - INSTITUTO  LELOIR\n",
            "Cantidad: 100  Estación: 029 - Parque Centenario\n",
            "Cantidad: 100  Estación: 066 - Billinghurst\n",
            "Cantidad: 100  Estación: 017 - Plaza Almagro\n",
            "Cantidad: 98  Estación: 096 - Carlos Gardel\n",
            "Cantidad: 97  Estación: 194 - PERÓN Y ACUÑA DE FIGUEROA\n",
            "Cantidad: 97  Estación: 030 - Peña\n",
            "Cantidad: 95  Estación: 069 - Ecuador\n",
            "Cantidad: 94  Estación: 054 - Acuña de Figueroa\n",
            "Cantidad: 93  Estación: 025 - Plaza Guemes\n",
            "Cantidad: 90  Estación: 200 - AUSTRIA Y FRENCH\n",
            "Cantidad: 89  Estación: 144 - PUEYRREDÓN\n",
            "Cantidad: 89  Estación: 033 - Facultad de Medicina\n",
            "Cantidad: 87  Estación: 130 - RETIRO II\n",
            "Cantidad: 85  Estación: 255 - BARRANCAS DE BELGRANO\n",
            "Cantidad: 84  Estación: 292 - PLAZA BOLIVIA\n",
            "Cantidad: 83  Estación: 059 - Coronel Diaz\n",
            "Cantidad: 82  Estación: 129 - Velasco\n",
            "Cantidad: 82  Estación: 131- HOSPITAL DE CLÍNICAS\n",
            "Cantidad: 81  Estación: 121 - YATAY\n",
            "Cantidad: 81  Estación: 160 - Godoy Cruz y Libertador\n",
            "Cantidad: 81  Estación: 099 - Malabia\n",
            "Cantidad: 81  Estación: 020 - Distrito Audiovisual\n",
            "Cantidad: 80  Estación: 083 - Paraná\n",
            "Cantidad: 80  Estación: 008 - Congreso\n",
            "Cantidad: 79  Estación: 171 - Pasteur\n",
            "Cantidad: 78  Estación: 065 - Julián Álvarez\n",
            "Cantidad: 77  Estación: 135 - MARCELO T. DE ALVEAR\n",
            "Cantidad: 75  Estación: 136 - Acevedo\n",
            "Cantidad: 75  Estación: 159 - Fitz Roy & Gorriti\n",
            "Cantidad: 73  Estación: 075 - Plaza Primero de Mayo\n",
            "Cantidad: 73  Estación: 125 - F.J.Santamaria de Oro\n",
            "Cantidad: 72  Estación: 182 - RAVIGNANI Y GUATEMALA\n",
            "Cantidad: 71  Estación: 085 - AGUERO\n",
            "Cantidad: 70  Estación: 381 - Matienzo Y Arce\n",
            "Cantidad: 69  Estación: 167 - Hipólito Yrigoyen\n",
            "Cantidad: 69  Estación: 174 - MINISTERIO DE EDUCACION\n",
            "Cantidad: 68  Estación: 243 - PLAZOLETA CELEDONIO FLORES\n",
            "Cantidad: 67  Estación: 158 - VILLARROEL\n",
            "Cantidad: 67  Estación: 156 - Plaza Alemania\n",
            "Cantidad: 66  Estación: 199 - ESTADOS UNIDOS Y BOEDO\n",
            "Cantidad: 65  Estación: 256 - PLAZA NORUEGA\n",
            "Cantidad: 65  Estación: 001 - FACULTAD DE DERECHO\n",
            "Cantidad: 65  Estación: 056 - Plaza Palermo Viejo\n",
            "Cantidad: 65  Estación: 181 - BILLINGHURST Y MANSILLA\n",
            "Cantidad: 65  Estación: 391 - Plaza República de Ecuador\n",
            "Cantidad: 65  Estación: 116 - HOSPITAL ALEMÁN\n",
            "Cantidad: 64  Estación: 012 - Plaza Vicente Lopez\n",
            "Cantidad: 64  Estación: 142 - Armenia y Gorriti\n",
            "Cantidad: 63  Estación: 260 - SAN MIGUEL DE GARICOITS\n",
            "Cantidad: 63  Estación: 399 - GARCIA DEL RIO\n",
            "Cantidad: 62  Estación: 124 - UGARTECHE\n",
            "Cantidad: 62  Estación: 163 - ONCE II\n",
            "Cantidad: 61  Estación: 276 - PRIMERA JUNTA\n",
            "Cantidad: 60  Estación: 104 - Federico Lacroze\n",
            "Cantidad: 59  Estación: 183 - VIRREY CEVALLOS\n",
            "Cantidad: 59  Estación: 384 - PLAZA BENITO NAZAR\n",
            "Cantidad: 58  Estación: 223 - GAINZA\n",
            "Cantidad: 58  Estación: 076 - Ayacucho\n",
            "Cantidad: 57  Estación: 227 -Club Ciudad de Buenos Aires\n",
            "Cantidad: 57  Estación: 100 - Plaza Gurruchaga\n",
            "Cantidad: 56  Estación: 093 - CARLOS CALVO\n",
            "Cantidad: 56  Estación: 082 - HOSPITAL ITALIANO\n",
            "Cantidad: 56  Estación: 242 - Plazoleta Rafael del Riego\n",
            "Cantidad: 55  Estación: 094 - GÚZMAN\n",
            "Cantidad: 55  Estación: 352 - San Jose de Flores\n",
            "Cantidad: 54  Estación: 275 - PLAZA 24 DE SEPTIEMBRE\n",
            "Cantidad: 54  Estación: 071 - CERRITO\n",
            "Cantidad: 54  Estación: 070 - ARAOZ\n",
            "Cantidad: 53  Estación: 189 - POSADAS\n",
            "Cantidad: 51  Estación: 150 - RODRIGO BUENO\n",
            "Cantidad: 49  Estación: 095 - ESMERALDA\n",
            "Cantidad: 49  Estación: 187 - Jose Maria Moreno\n",
            "Cantidad: 48  Estación: 146 - Hospital Francés\n",
            "Cantidad: 48  Estación: 190 - JUNCAL\n",
            "Cantidad: 47  Estación: 186 - MANZANA 66\n",
            "Cantidad: 47  Estación: 162 - LARREA Y BARTOLOMÉ MITRE\n",
            "Cantidad: 47  Estación: 165 - PLAZA MONSEÑOR MIGUEL DE ANDREA\n",
            "Cantidad: 46  Estación: 350 - Plaza Irlanda\n",
            "Cantidad: 46  Estación: 045 - Uruguay\n",
            "Cantidad: 46  Estación: 103 - MALBA\n",
            "Cantidad: 46  Estación: 084 - Lavalle\n",
            "Cantidad: 45  Estación: 089 - Cabello\n",
            "Cantidad: 45  Estación: 257 - Plaza Francisco Ramirez\n",
            "Cantidad: 45  Estación: 016 - Legislatura\n",
            "Cantidad: 45  Estación: 188 - Aranguren\n",
            "Cantidad: 45  Estación: 087 - Guayaquil\n",
            "Cantidad: 44  Estación: 022 - Arenales\n",
            "Cantidad: 44  Estación: 038 - Plaza Libertad\n",
            "Cantidad: 43  Estación: 046 - Chile\n",
            "Cantidad: 43  Estación: 285 - ESPINOSA\n",
            "Cantidad: 43  Estación: 331 - CALIFORNIA\n",
            "Cantidad: 43  Estación: 117 - HUMBERTO 1°\n",
            "Cantidad: 42  Estación: 254 - Plaza Rafael Hernandez\n",
            "Cantidad: 42  Estación: 206 - Galicia\n",
            "Cantidad: 41  Estación: 064 - RIOBAMBA\n",
            "Cantidad: 41  Estación: 335 - General Urquiza\n",
            "Cantidad: 41  Estación: 086 - SAAVEDRA\n",
            "Cantidad: 41  Estación: 050 - Hospital Rivadavia\n",
            "Cantidad: 41  Estación: 003 - ADUANA\n",
            "Cantidad: 40  Estación: 251 - Solar de la Abadía\n",
            "Cantidad: 40  Estación: 272 - Plaza Bruno Giordano\n",
            "Cantidad: 40  Estación: 132 - CORRIENTES\n",
            "Cantidad: 40  Estación: 281 - Villa Urquiza\n",
            "Cantidad: 40  Estación: 128 - PARQUE DEL BAJO\n",
            "Cantidad: 40  Estación: 233 - MONROE\n",
            "Cantidad: 40  Estación: 058 - Ministro Carranza\n",
            "Cantidad: 39  Estación: 270 - PLAZA DEL ANGEL GRIS\n",
            "Cantidad: 39  Estación: 152 - JULIETA LANTERI\n",
            "Cantidad: 39  Estación: 258 - Plaza J.J. Paso\n",
            "Cantidad: 39  Estación: 193 - ARENALES Y AGUERO\n",
            "Cantidad: 38  Estación: 178 - José Marmol\n",
            "Cantidad: 38  Estación: 151 - AIME PAINÉ\n",
            "Cantidad: 38  Estación: 289 - MONTAÑESES\n",
            "Cantidad: 38  Estación: 240 - ECHEVERRIA\n",
            "Cantidad: 37  Estación: 229 - RIGLOS\n",
            "Cantidad: 37  Estación: 101 - Fitz Roy\n",
            "Cantidad: 37  Estación: 336 - La Pampa\n",
            "Cantidad: 36  Estación: 023 - Suipacha\n",
            "Cantidad: 36  Estación: 282 - Tronador\n",
            "Cantidad: 36  Estación: 091 - Pasco\n",
            "Cantidad: 36  Estación: 166 - Cementerio de Recoleta\n",
            "Cantidad: 36  Estación: 169 - FACULTAD DE PSICOLOGIA\n",
            "Cantidad: 36  Estación: 273 - Plazoleta Colombia\n",
            "Cantidad: 35  Estación: 249 - Balbín\n",
            "Cantidad: 35  Estación: 027 - Montevideo\n",
            "Cantidad: 35  Estación: 261 - QUINTEROS LIDORO\n",
            "Cantidad: 34  Estación: 250 - Fleni\n",
            "Cantidad: 34  Estación: 013 - ONCE\n",
            "Cantidad: 33  Estación: 111 - MACACHA GUEMES\n",
            "Cantidad: 33  Estación: 092 - Salcedo\n",
            "Cantidad: 33  Estación: 112 - 9 de Julio\n",
            "Cantidad: 33  Estación: 349 - Plaza Saenz Peña\n",
            "Cantidad: 32  Estación: 365 - Venancio Flores\n",
            "Cantidad: 32  Estación: 073 - Ruy Díaz de Guzmán\n",
            "Cantidad: 32  Estación: 153 - JUAN MANUEL DE BLANES\n",
            "Cantidad: 32  Estación: 120 - HOSPITAL RAMOS MEJIA\n",
            "Cantidad: 32  Estación: 264 - Plaza Marcos Sastre\n",
            "Cantidad: 31  Estación: 044 - Ecoparque\n",
            "Cantidad: 31  Estación: 063 - Reconquista\n",
            "Cantidad: 31  Estación: 205 - SAN MARTIN\n",
            "Cantidad: 31  Estación: 374 - Puan\n",
            "Cantidad: 30  Estación: 007 - OBELISCO\n",
            "Cantidad: 30  Estación: 259 - PLAZA CASTELLI\n",
            "Cantidad: 30  Estación: 079 - AZUCENA VILLAFLOR\n",
            "Cantidad: 29  Estación: 006 - Parque Lezama\n",
            "Cantidad: 28  Estación: 278 - Donato Alvarez\n",
            "Cantidad: 28  Estación: 118 - MEXICO\n",
            "Cantidad: 26  Estación: 244 - UADE\n",
            "Cantidad: 26  Estación: 032 - Catedral\n",
            "Cantidad: 26  Estación: 149 - LIMA\n",
            "Cantidad: 25  Estación: 396 - PLAZA ALBERTI\n",
            "Cantidad: 25  Estación: 346 - Plaza Zapiola\n",
            "Cantidad: 25  Estación: 297 - TRONADOR Y GARCÍA DEL RÍO\n",
            "Cantidad: 25  Estación: 004 - Plaza Roma\n",
            "Cantidad: 25  Estación: 222 - SIMON BOLIVAR\n",
            "Cantidad: 25  Estación: 080 - DOBLAS\n",
            "Cantidad: 25  Estación: 037- CLAUDIA PÍA BRAUDACCO\n",
            "Cantidad: 24  Estación: 155 - Parque José Evaristo Uriburu\n",
            "Cantidad: 24  Estación: 248 - Husares\n",
            "Cantidad: 23  Estación: 164 - FACULTAD DE INGENERIA\n",
            "Cantidad: 23  Estación: 024 - ALSINA\n",
            "Cantidad: 22  Estación: 107 - HOSPITAL GARRAHAN\n",
            "Cantidad: 22  Estación: 041 - Urquiza y Rondeau\n",
            "Cantidad: 21  Estación: 137 - AZOPARDO Y CHILE\n",
            "Cantidad: 21  Estación: 061-Ministerio de Economia\n",
            "Cantidad: 21  Estación: 394 - Av. La Plata\n",
            "Cantidad: 21  Estación: 196 - HOSPITAL ARGERICH\n",
            "Cantidad: 20  Estación: 268 - Plaza Aristóbulo Del Valle\n",
            "Cantidad: 20  Estación: 034 - Colonia Express\n",
            "Cantidad: 20  Estación: 126 - Ministerio de Justicia y Seguridad\n",
            "Cantidad: 20  Estación: 036 - MAIPÚ\n",
            "Cantidad: 20  Estación: 002 - Retiro I\n",
            "Cantidad: 20  Estación: 035 - INGENIERO BUTTY\n",
            "Cantidad: 20  Estación: 049 - 33 Orientales\n",
            "Cantidad: 19  Estación: 237 - Madero Office\n",
            "Cantidad: 19  Estación: 172 - BRASIL\n",
            "Cantidad: 19  Estación: 184 - Pedro Echague\n",
            "Cantidad: 19  Estación: 026 - JUANA MANSO I\n",
            "Cantidad: 19  Estación: 138 - Hospital Britanico\n",
            "Cantidad: 19  Estación: 387 - Luna\n",
            "Cantidad: 18  Estación: 218 - Campana\n",
            "Cantidad: 18  Estación: 140 - Las Casas\n",
            "Cantidad: 18  Estación: 330 - Parque Avellaneda\n",
            "Cantidad: 17  Estación: 393 - Barrio 31\n",
            "Cantidad: 17  Estación: 021 - Parque Patricios\n",
            "Cantidad: 16  Estación: 215 - HOSPITAL ALVAREZ\n",
            "Cantidad: 16  Estación: 108 - Usina del Arte\n",
            "Cantidad: 16  Estación: 324 - Las Victorias\n",
            "Cantidad: 16  Estación: 395 - Agronomia II\n",
            "Cantidad: 16  Estación: 168 - Estados Unidos\n",
            "Cantidad: 15  Estación: 280 - JURAMENTO\n",
            "Cantidad: 15  Estación: 334 - CENTRO DE EXPOSICIONES\n",
            "Cantidad: 15  Estación: 060 - 25 De Mayo\n",
            "Cantidad: 14  Estación: 221 - CULPINA\n",
            "Cantidad: 13  Estación: 097 - Avelino Diaz\n",
            "Cantidad: 13  Estación: 225 - HOSPITAL TORNU\n",
            "Cantidad: 13  Estación: 252 - Tamborini\n",
            "Cantidad: 12  Estación: 213 - Hospital Alvear\n",
            "Cantidad: 12  Estación: 313 - De Los Incas\n",
            "Cantidad: 12  Estación: 378 - AGRONOMIA\n",
            "Cantidad: 12  Estación: 322 - MARTÍ Y DIRECTORIO\n",
            "Cantidad: 12  Estación: 179 - CASA SAN\n",
            "Cantidad: 11  Estación: 051 - TUCUMAN\n",
            "Cantidad: 10  Estación: 316 - Buenos Aires\n",
            "Cantidad: 10  Estación: 197 - PLAZA CIUDAD DE UDINE\n",
            "Cantidad: 10  Estación: 204 - Biarritz\n",
            "Cantidad: 10  Estación: 373 - Jorgelina De Simone\n",
            "Cantidad: 10  Estación: 018 - Independencia\n",
            "Cantidad: 10  Estación: 340 - PLAZA NUEVA POMPEYA\n",
            "Cantidad: 9  Estación: 354 - José Martí\n",
            "Cantidad: 9  Estación: 363 - Udaondo\n",
            "Cantidad: 8  Estación: 203 - Beiro\n",
            "Cantidad: 8  Estación: 277 - Coghlan\n",
            "Cantidad: 8  Estación: 348 - Villa del Parque\n",
            "Cantidad: 8  Estación: 207 - PLAZA ARENALES\n",
            "Cantidad: 7  Estación: 305 - Plaza Martin Rodriguez\n",
            "Cantidad: 6  Estación: 361 - Plaza Don Segundo Sombra\n",
            "Cantidad: 6  Estación: 367 - Eva Perón\n",
            "Cantidad: 6  Estación: 191 - Rivadavia y 9 de Julio\n",
            "Cantidad: 6  Estación: 370 - Beauchef\n",
            "Cantidad: 5  Estación: 114 - DELLA PAOLERA\n",
            "Cantidad: 1  Estación: 309 - UTN II\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1sjCcKvHFrD"
      },
      "source": [
        "## $\\medio$ El tiempo es dinero\n",
        "\n",
        "*   ***Analisís de información estructurada***\n",
        "*   ***Librerías***\n",
        "\n",
        "La administración del dinero es una tarea que requiere una altísima fiabilidad. \n",
        "En esta ocasión tu objetivo será programar un script que **actualice la cantidad** de dinero de una serie de usuarios a partir de la información de las transferencias que fueron realizadas. \n",
        "Más concretamente recibiras una **base de datos con la cantidad de dinero de una serie de usuarios**, un base de datos con una serie de transferencias que los usuarios se realizan entre si, y deberás generar con eso **una nueva base de datos con el dinero actualizado de cada usuario**.\n",
        "\n",
        "*   Importar el archivo **Finanzas.xlsx** que contiene la cantidad de dinero de los usuarios y las transferencias en dos hojas de archivo.\n",
        "*   Exportar un archivo **usuarios_actualizados.xlsx** que contiene las cantidades de dinero actualizadas.\n",
        "\n",
        "<img src=\"https://psmag.com/.image/t_share/MTI3NTgyMzg2MzE2NzAxNjY2/time-is-money.jpg\" width=400>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxggKFg1HLLp"
      },
      "source": [
        "! wget \"https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/Finanzas.xlsx\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCM6UYHPGIdl"
      },
      "source": [
        "Debes procesar las transferencias y actualizar el saldo de cada usuario (crear un nuevo archivo excel con los saldos actualizados)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfFURx2aB_ge"
      },
      "source": [
        "### **Solución**\n",
        "\n",
        "La solución consiste en leer la información de los usuarios y las transferencias, realizar la actualización de los dineros de los usuarios a partir de las transferencias y luego almacenar el resultado en un archivo de excel.\n",
        "\n",
        "Más en contreto, necesitamos procesar las transferencias una por una, Entonces las leemos en formato de **records** ya que solo necesitamos iterarlas, es decir, no es necesario indexarlas por alguna columna (Aunque se podría)\n",
        "\n",
        "Luego leemos los usuarios en formato de **index** ya que nos interesa indexar los usuarios por su nombre. Como es necesario hacer actualizaciones de los saldos de los usuarios es necesario poder acceder agilmente a los usuarios por su nombre (Que es el identificar utilizado en las transferencias)\n",
        "\n",
        "Entonces procesamos las trasnferencias una por una, actualizamos los campos correspondientes de cada usuario involucrado en cada transferencia (Es decir le sacamos el dinero al usuario que hizó la transferencia, se lo agregamos al que la recibio).\n",
        "\n",
        "El ultimo paso es almacenar los resultados en un nuevo archivo excel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUbf2gWaAxri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d0ae77-da8c-46c7-eece-91d861c89629"
      },
      "source": [
        "#leemos los usuarios en el formato index, para tenerlos indexados por el nombre de usuario\n",
        "#Es decir, para que la clave sea el nombre de los usuarios y sea facil referenciar\n",
        "#a los usuarios\n",
        "usuarios_archivo = pd.read_excel(\"Finanzas.xlsx\", \"Usuarios\",index_col=\"Usuario\") \n",
        "\n",
        "#Mostramos los usuarios recien leidos\n",
        "print(\"Usuarios:\")\n",
        "print(usuarios_archivo)\n",
        "print(\" \")\n",
        "\n",
        "usuarios = usuarios_archivo.to_dict(\"index\")\n",
        "\n",
        "\n",
        "#Leemos las transferencias en el formato records, es decir conseguimos una lista con las transferencias\n",
        "transferencias_archivo = pd.read_excel(\"Finanzas.xlsx\", \"Transferencias\")\n",
        "transferencias = transferencias_archivo.to_dict(\"records\")\n",
        "\n",
        "#Mostramos las transferencias recien realizadas\n",
        "print(\"Transferencias:\")\n",
        "print(transferencias_archivo)\n",
        "print(\" \")\n",
        "\n",
        "for transferencia in transferencias: # iteramos todas las transferncias distintas\n",
        "    # obtenemos la info de la transferencia\n",
        "    emisor = transferencia[\"Emisor\"]\n",
        "    receptor = transferencia[\"Receptor\"]\n",
        "    monto = transferencia[\"Monto\"]\n",
        "\n",
        "    usuarios[emisor][\"Presupuesto\"] -= monto # le retiramos el dinero al emisor\n",
        "    usuarios[receptor][\"Presupuesto\"] += monto #le ortorgamos el dinero al receptor\n",
        "\n",
        "# generamos el nuevo archivo excel, orient=\"index\" provoca que las claves se coloquen en la primera fila,\n",
        "# En este caso los usuarios son las claves y queremos que la primerea fila del archivo\n",
        "# tenga todos los nombres de usuario\n",
        "usuarios_actualizados = pd.DataFrame.from_dict(usuarios, orient=\"index\")\n",
        "\n",
        "#Mostramos los saldos de los usuarios luego de realizar las transferencias\n",
        "print(\"Usuarios luego de realizar las transferencias:\")\n",
        "print(usuarios_actualizados)\n",
        "\n",
        "#Grabamos la información final\n",
        "usuarios_actualizados.to_excel(\"usuarios_actualizados.xlsx\")\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usuarios:\n",
            "         Edad  Presupuesto\n",
            "Usuario                   \n",
            "Claudia    43        43433\n",
            "Agustin    22        23432\n",
            "Rocio      25        65444\n",
            "Ariel      34        76533\n",
            "Joaquin    65        34521\n",
            "Uriel      43        23422\n",
            "Martin     32        34534\n",
            "Andrés     26        23423\n",
            " \n",
            "Transferencias:\n",
            "    Emisor Receptor   Monto Efectuada\n",
            "0  Claudia    Ariel     220        No\n",
            "1    Rocio    Ariel    2000        No\n",
            "2  Agustin    Rocio   43434        No\n",
            "3    Uriel  Joaquin   12423        No\n",
            "4   Martin   Andrés  234223        No\n",
            "5  Joaquin    Ariel   23323        No\n",
            " \n",
            "Usuarios luego de realizar las transferencias:\n",
            "         Edad  Presupuesto\n",
            "Claudia    43        43213\n",
            "Agustin    22       -20002\n",
            "Rocio      25       106878\n",
            "Ariel      34       102076\n",
            "Joaquin    65        23621\n",
            "Uriel      43        10999\n",
            "Martin     32      -199689\n",
            "Andrés     26       257646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CmN7SuE6ml-"
      },
      "source": [
        "## $\\dificil $ Buscando la $\n",
        "\n",
        "\n",
        "*   ***Procesamiento de información estructurada***\n",
        "*   ***Librerías***\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYHHRHbG7KEl"
      },
      "source": [
        "Utilizando el set de datos del archivo **california_housing_train.xlsx**\n",
        "\n",
        "Dividir el area cubierta por el censo en cuadrantes de 0.5 de latitud x 0.5  de longitud, encontrar para que cuadrante el valor medio de 'median_house_value' es máximo. Asignar el paso como una variable para que pueda cambiarse facilmente. Para filtrar las zonas de muy baja residencia descarten los valores cuando hay menos de 100 casas\n",
        "\n",
        "Datos utiles:\n",
        "- Minimo de longitud: -124.3\n",
        "- Máximo de longitud: -114.3\n",
        "- Minimo de latitud: 32.5\n",
        "- Máximo de latitud: 42.5\n",
        "\n",
        "Tip: El programa va a tardar en correr, no se asusten!\n",
        "\n",
        "**Nota final**: Busquen en el mapa estas coordenadas para ver donde quedan! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBqqwHhpCCWv"
      },
      "source": [
        "### **Solución**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p72kPtc3kn19"
      },
      "source": [
        "# Importar el archivo california_housing_train.xlsx.\n",
        "! wget \"https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/california_housing_train.xlsx\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFNVBCai692J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6cc745a-2b2c-4bbe-c52a-21ce5da29289"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "archivo = pd.read_excel(\"california_housing_train.xlsx\") \n",
        "paso = .5\n",
        "\n",
        "lats = np.arange(32.5,42.5,paso)\n",
        "lons = np.arange(-124.3,113.3,paso) \n",
        "maximoValor = 0\n",
        "maximaLat = 0\n",
        "maximaLon = 0\n",
        "for lat in lats:\n",
        "    for lon in lons:\n",
        "        data = archivo[(archivo['latitude']>=lat) & (archivo['latitude']<=lat+paso)]\n",
        "        data = data[(data['longitude']>=lon) & (data['longitude']<=lon+paso)]\n",
        "        if(len(data)>100):\n",
        "            m = np.mean(data['median_house_value'])\n",
        "            if m > maximoValor:\n",
        "                maximaLat = lat\n",
        "                maximaLon = lon\n",
        "                maximoValor = m\n",
        "                \n",
        "print('Latitude:',maximaLat,'Longitude',maximaLon,'Price',maximoValor)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latitude: 34.0 Longitude -119.8 Price 332157.1842105263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLO8x3xOnn5r"
      },
      "source": [
        "## $\\imposible $ Unificación de bases de datos\n",
        "\n",
        "El objetivo de este problema es unificar dos bases de datos que contienen mails. Esto quiere decir, tomar dos bases de datos de formato csv **lista1.csv** y **lista2.csv** y fusionarnos en una misma base de datos **listafinal.csv**. \n",
        "El contenido de las bases de datos son listas de mails, que contienen mails y otras informaciones de distintos usuarios. Tener en cuenta que las dos bases de datos pueden tener informaciones distintas de los usuarios.\n",
        "\n",
        "**Recomendamos** descargar los archivos para ver su contenido (Con excel pueden abrirlos, pensar que un csv es prácticamente equivalente a un excel).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq40RyOZnr9y"
      },
      "source": [
        "! wget \"https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/lista1.csv\" \n",
        "# primera lista de clientes\n",
        "\n",
        "! wget \"https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/lista2.csv\"\n",
        "# segunda lista de clientes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aVXwvQLJGwo"
      },
      "source": [
        "### **Solución**\n",
        "Este es un problema con una solucion que puede parecer tediosa pero resuelve un problema muy común y su lógica luego puede aplicarse a otros casos similares.\n",
        "\n",
        "La solución propuesta consiste en armar una nueva base de datos con los **contenidos combinados** de los usuarios acorde a la información extraida de las dos bases de datos originales.\n",
        "\n",
        "Para esto se debe crear una nueva de base de datos unificada a la que le iremos progresivamente agregando los valores primero de la base de datos 1 **lista1.csv** y en segundo lugar los valores de la base de datos 2 **lista2.csv**. \n",
        "\n",
        "Esta nueva de base de datos unificada tendrá la forma de un diccionario donde las claves serán los mails de los usuarios y el contenido la información de cada usuario (es decir el mismo formato que las bases de datos originales)\n",
        "\n",
        "Hay que tener una consideración que es que en las bases de datos **lista1.csv** y **lista2.csv** la información que se tiene de los usuarios puede ser distinta. Por ejemplo, si en la lista1 tenemos como información la edad de los usuarios en una columna puede pasar que en la lista2 no este.\n",
        "\n",
        "Entonces es importante ir almacenando en un set (todosloscampos) todos los campos (es decir las columnas) que vamos encontrando en un set que va almacenanado progresivamente todos los campos que vamos encontrando en las bases de datos. Tiene que ser un set para evitar la repetición de campos en la base de datos final."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5EmrJu9nolT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d4ae64b-0949-4a22-89fd-540b7f9b21b4"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# aca almacenamos las bases de datos que vamos a unificar\n",
        "listas = [ \"lista1.csv\", \"lista2.csv\" ]\n",
        "\n",
        "# en este diccionario vamos a ir amlacenando la información de la base de datos unificada\n",
        "# la clave son los mails, el contenido la información de los usuarios\n",
        "\n",
        "clientes = dict() \n",
        "\n",
        "#en este set almacenamos todas las columnas que se van progresivamente encontrando\n",
        "todosloscampos = set() #set=conjunto\n",
        "\n",
        "\n",
        "for lista in listas: # iteramos todas las bases de datos \n",
        "\n",
        "    # leemos el contenido indexando por mail (es decir la clave de los diccionarios será el mail de los usuarios)\n",
        "    archivo = pd.read_csv(lista, index_col =[\"Mail\"])\n",
        "    data = archivo.to_dict(\"index\") \n",
        "    \n",
        "    # mostramos en pantalla\n",
        "    print(\"Base de datos\", lista)\n",
        "    print(archivo)\n",
        "\n",
        "    # iteramos los mails de la base de datos\n",
        "    for mail in data: \n",
        "        # si el mail es uno nuevo para nuetra base de datos unificada, lo inicializamos como un diccionario vacio sin información\n",
        "        # la cual se la agregaremos despues\n",
        "        # si el mail ya existe no es necesario, significa que lo vimos en una base de datos anterior\n",
        "\n",
        "        if mail not in clientes: \n",
        "            clientes[mail] = dict() \n",
        "        \n",
        "        # leemos todos los campos (las columnas) que tenemos del mail en la base de datos original que estamos procesando\n",
        "        campos = data[mail]\n",
        "\n",
        "        # iteramos todos los campos del mail encontrado, y le asignamos sus valores en la base de datos unificada\n",
        "        for campo in campos:\n",
        "            # le asignamos a \"clientes\" que es la base de datos unificada el campo actual\n",
        "            # que esta en data[mail], que tiene la información de la base de datos que estamos procesando del\n",
        "            # campo correspondiente \n",
        "            clientes[mail][campo] = data[mail][campo]\n",
        "\n",
        "            # le agregamos al set de campos (columas) el campo encontrado\n",
        "            # como es un set los repetidos no van a agregarse\n",
        "            todosloscampos.add(campo)\n",
        "\n",
        "    print(\"  \")\n",
        "            \n",
        "# Por ultimo escribimos el archivo final, colocando las claves de los elementos de la base unificada (es decir los mails)\n",
        "# En la primera columna (por eso orient=\"index\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(clientes, orient='index')\n",
        "\n",
        "# Mostramos los resultados y los guardamos en un archivo final\n",
        "print(\"Base de datos unificada\")\n",
        "print(df)\n",
        "\n",
        "df.to_csv('listafinal.csv')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base de datos lista1.csv\n",
            "                     Apellido    Nombre  Edad\n",
            "Mail                                         \n",
            "druschel@msn.com     Druschel   Julieta    31\n",
            "hstiles@hotmail.com    Stiles     Harry    23\n",
            "jrifkin@gmail.com      Rifkin  Josefina    27\n",
            "  \n",
            "Base de datos lista2.csv\n",
            "                       Nombre Apellido       DNI\n",
            "Mail                                            \n",
            "payned@icloud.com       Pedro    Ayned  23569875\n",
            "johnh@comcast.net        John   Harris  99852365\n",
            "fairbank@icloud.com  Fernanda  Airbank  99754231\n",
            "jrifkin@gmail.com    Josefina   Rifkin  40896523\n",
            "  \n",
            "Base de datos unificada\n",
            "                     Apellido    Nombre  Edad         DNI\n",
            "druschel@msn.com     Druschel   Julieta  31.0         NaN\n",
            "hstiles@hotmail.com    Stiles     Harry  23.0         NaN\n",
            "jrifkin@gmail.com      Rifkin  Josefina  27.0  40896523.0\n",
            "payned@icloud.com       Ayned     Pedro   NaN  23569875.0\n",
            "johnh@comcast.net      Harris      John   NaN  99852365.0\n",
            "fairbank@icloud.com   Airbank  Fernanda   NaN  99754231.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRvegpwLICIN"
      },
      "source": [
        "# Anexos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmqpWNphG0To"
      },
      "source": [
        "### **Opcional**: Mini-desafío json\n",
        "Estás encargado de un servidor con millones de usuarios. \n",
        "\n",
        "Se pide escribir un programa que reciba el email y contraseña del usuario y se fije si existe el usuario y si coincide la contraseña.\n",
        "\n",
        "Se tienen datos encolumnados en formato json que nos llegan del siguiente formato:\n",
        "```json\n",
        "{\n",
        "\t\"usuarios\": [\"mica@mail.co\", \"jerry@gma.com\",\"alber@soup.co\"],\n",
        "\t\"contra\": [\"abc123\",\"caballitos\",\"yoloswag\"]\n",
        "}\n",
        "```\n",
        "La entrada del programa son tres lineas, el programa entonces va tener tres `input()`. La primer linea contiene el `json`, la segunda el `email` a verificar, y la tercera la `contraseña`. Por ende, las primeras lineas de su programa podrían ser:\n",
        "```python\n",
        "import json\n",
        "usuarios = json.loads(input())\n",
        "email = input()\n",
        "password = input()\n",
        "```\n",
        "\n",
        "La salida del programa será `OK` si el usuario **se encuentra en la base de datos** ***y*** **si coincide la contraseña**, imprimimos `DNE` (does not exist) si el usuario no existe y `NO` en cualquier otro caso.\n",
        "\n",
        "#### Caso ejemplo\n",
        "**Entrada**:\n",
        "```plaintext\n",
        "{\"usuarios\": [\"mica@mail.co\",\"jerry@gma.com\",\"alber@soup.co\"],\"contra\": [\"abc123\",\"caballitos\",\"yoloswag\"]}\n",
        "mica@mail.co\n",
        "caballitos\n",
        "```\n",
        "El usuario existe y la contraseña también... pero no le corresponde la contraseña `caballitos` al usuario `mica@mail.co` (la contraseña de `mica@mail.co` sería `abc123`) por ende imprimimos:\n",
        "\n",
        "**Salida**\n",
        "```\n",
        "NO\n",
        "```\n",
        "\n",
        "_Considere que no hay usuarios repetidos_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxTgxk0tIRpw"
      },
      "source": [
        "### **Solución**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EZhTLiCk0BI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "223f9fd4-8135-4222-f567-3c11012b9821"
      },
      "source": [
        "import json\n",
        "usuarios = json.loads(input())\n",
        "email = input(\"Mail:\")\n",
        "password = input(\"Contraseña\")\n",
        "\n",
        "if email in usuarios[\"usuarios\"]:\n",
        "  index = usuarios[\"usuarios\"].index(email)\n",
        "  if password == usuarios[\"contra\"][index]:\n",
        "    print(\"OK\")\n",
        "  else:\n",
        "    print(\"NO\")\n",
        "\n",
        "else:\n",
        "  print(\"DNE\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"usuarios\": [\"mica@mail.co\",\"jerry@gma.com\",\"alber@soup.co\"],\"contra\": [\"abc123\",\"caballitos\",\"yoloswag\"]}\n",
            "Mail:mica@mail.co\n",
            "Contraseñacaballitos\n",
            "NO\n"
          ]
        }
      ]
    }
  ]
}